<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="../katex/katex.min.js"></script><link rel="stylesheet" href="../katex/katex.min.css" /><script type="text/javascript">window.onload = function(){var mathElements = document.getElementsByClassName("math");
  for (var i=0; i < mathElements.length; i++)
  {
   var texText = mathElements[i].firstChild
   katex.render(texText.data, mathElements[i])
  }}
  </script>
</head>
<body>
<p><link rel=stylesheet href=../style.css></p>
<h1 id="fundamental">fundamental</h1>
<h2 id="symbols">symbols</h2>
<table>
<thead>
<tr class="header">
<th align="center">Symbol</th>
<th align="left">description</th>
<th align="center">name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\Omega</span></td>
<td align="left">all possible outcomes</td>
<td align="center">sample space</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\omega</span></td>
<td align="left"><span class="math inline">\omega \in \Omega</span></td>
<td align="center">a sample point</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">A</span></td>
<td align="left"><span class="math inline">A \subseteq \Omega</span></td>
<td align="center">an event</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">P</span></td>
<td align="left">probability function</td>
<td align="center">--</td>
</tr>
</tbody>
</table>
<h2 id="axioms">3 axioms</h2>
<ol style="list-style-type: decimal">
<li>probability of an event is between 0 and 1
<ul>
<li><span class="math inline">0 \leq P(A) \leq 1</span></li>
</ul></li>
<li>probability of everything is 1; of nothing is 0
<ul>
<li><span class="math inline">P(\Omega) = 1</span></li>
<li><span class="math inline">P(\{\}) = 0</span></li>
</ul></li>
<li>probability adds up if events dont intersect (are pairwise disjoint)
<ul>
<li><span class="math inline">P(A_1 \cup A_2 \cup \dots) = P(A_1) + P(A_2) + \dots</span></li>
<li>note: only can union countably many events, so cant union stuff like real number range</li>
</ul></li>
</ol>
<h2 id="discussion">discussion</h2>
<ul>
<li>remember <span class="math inline">\Omega</span> is specifically <em>experiment outcomes</em>
<ul>
<li>even if coin possibilities is <span class="math inline">\{\text{Head}, \text{Tail}\}</span>, flipping two coins experiment is <span class="math inline">\Omega = \{(a, b) \mid a, b \in \{\text{Head}, \text{Tail}\}\}</span></li>
</ul></li>
<li><span class="math inline">P</span> called the <em>probability measure</em>, <em>probability distribution</em>, <em>probability</em>
<ul>
<li>when homework asks 'describe <span class="math inline">P</span>', probably wants to know, equally distributed?? if not, give function</li>
</ul></li>
<li>remember axiom 3 (add probabilities) only works if events DONT INTERSECT.
<ul>
<li>one hw problem was 'whats probability of pick 3 things w/ replacement, same <span class="math inline">1 \over 50</span> chance thing picked exactly 2 times?'
<ul>
<li>i thought 'ok is <span class="math inline">{1 \over 50} \cdot {1 \over 50} \cdot {50 \over 50} + {1 \over 50} \cdot {50 \over 50} \cdot {1 \over 50} + {50 \over 50} \cdot {1 \over 50} \cdot {1 \over 50}</span>'!!!</li>
<li>but actually not because the <span class="math inline">{1 \over 50} \cdot {1 \over 50} \cdot {1 \over 50}</span> case overlaps two times i believe. so must manually subtract <span class="math inline">2 \over 50^3</span>.</li>
</ul></li>
</ul></li>
<li>loose? notation: use <span class="math inline">P(\omega)</span> as? <span class="math inline">P(\{\omega\})</span>.</li>
</ul>
<h2 id="geometric-sum">geometric sum</h2>
<p><span class="math display">\displaystyle \sum_{k=0}^{n-1}ar^k = a \cdot {1-r^n \over 1-r}</span></p>
<h1 id="replacement">replacement</h1>
<ul>
<li>replace <span class="math inline">\rightarrow</span> number stay same</li>
<li>dont replace <span class="math inline">\rightarrow</span> number goes down</li>
</ul>
<h1 id="choosepick-binomial-coefficient">choose/pick (binomial coefficient)</h1>
<p>there are <span class="math inline">n \choose k</span> <span class="math inline">k</span>-sized subsets you can take out of an <span class="math inline">n</span>-sized superset (sets are unordered).</p>
<p><span class="math display">\displaystyle {n \choose k} = {n! \over {k! (n - k)!}}</span></p>
<h1 id="infinite-probability">infinite probability</h1>
<p>experiment: roll 6-side die infinitely. stop when get '4'. outcome is how many times you rolled!!</p>
<p><span class="math display">\displaystyle \Omega = \{1, 2, 3, 4, ...\} = \mathbb{N}</span></p>
<p>probability depends on how many times youve rolled so far..</p>
<p><span class="math display">\displaystyle \begin{aligned}
P(1) &amp;= {1 \over 6}\\
P(2) &amp;= ({5 \over 6}) \cdot {1 \over 6}\\
P(3) &amp;= ({5 \over 6} \cdot {5 \over 6}) \cdot {1 \over 6}\\
\dots \\
P(k) &amp;= ({5 \over 6})^{k - 1} \cdot {1 \over 6} = (\text{FailureProb})^{k - 1} \cdot \text{SuccessProb}
\end{aligned}</span></p>
<p><span class="math inline">P(\infty) = 0</span> either by taking limit (which always 0 because <span class="math inline">0 \lt \text{FailureProb} \lt 1</span>, so <span class="math inline">\lim\limits_{x \to \infty} \text{FailureProb}^x = 0</span>) or by reasoning with axiom 3</p>
<h1 id="sets">sets</h1>
<h2 id="cartesian-product">cartesian product</h2>
<p><span class="math display">\displaystyle S_1 \times S_2 = \{(a, b) \mid a \in S_1, b \in S_2\}</span></p>
<p><span class="math display">\displaystyle \# (S_1 \times S_2) = \# S_2 \cdot \# S_1</span></p>
<p><span class="math display">\displaystyle S \times S \times S = S^3</span></p>
<h2 id="complement-ac-of-event-a">complement <span class="math inline">A^c</span> of event <span class="math inline">A</span></h2>
<p><span class="math display">\displaystyle \begin{aligned}
A \cup A^c &amp;= \Omega \\
A \cap A^c &amp;= \{\}
\end{aligned}</span></p>
<p><span class="math display">\displaystyle P(\Omega) = 1 = P(A) + P(A^c)</span></p>
<h1 id="unionintersection-stuff">union/intersection stuff</h1>
<ul>
<li><span class="math inline">AB</span> short for <span class="math inline">A \cap B</span></li>
</ul>
<h2 id="de-morgan">De Morgan</h2>
<p><span class="math display">\displaystyle \begin{aligned}
(A \cup B)^c &amp;= A^c \cap B^c \\
(A \cap B)^c &amp;= A^c \cup B^c
\end{aligned}</span></p>
<h2 id="axiom-3-for-sets-that-intersect">axiom 3 for sets that intersect</h2>
<p><span class="math display">\displaystyle \begin{aligned}
\\ P(\text{union of sets}) &amp;= P\text{ sum} - \text{all intersections}
\\ P(A \cup B) &amp;= P(A) + P(B) - P(A \cap B)
\\ P(A \cup B \cup C) &amp;= P(A) + P(B) + P(C) - P(AB) - P(BC) - P(AC)
\\ \dots
\end{aligned}</span></p>
<h1 id="random-variables">'random variables'</h1>
<p><span class="math display">\displaystyle X : \omega \to \mathbb{R}</span></p>
<p>represented by capital letter. maps a sample point to a number. weird loose notation. <span class="math inline">X</span> by itself can mean like 'an output of <span class="math inline">X</span>' or <span class="math inline">X</span> itself??</p>
<p><span class="math inline">p(k)</span> is <span class="math inline">P(X = k)</span>, called <em>probability mass function</em></p>
<h1 id="rangesgeometry-stuff">ranges/geometry stuff</h1>
<p>geometry</p>
<h1 id="given">given</h1>
<p>prob of A given B: <span class="math inline">P(A \mid B)</span></p>
<p><span class="math display">\displaystyle P(A \mid B) = {P(A \cap B) \over P(B)}</span></p>
<h1 id="misc-useful-identities">misc useful identities</h1>
<p><span class="math display">\displaystyle P(A) = P(A \cap B) + P(A \cap B^c)</span></p>
<h1 id="partitioned-omega">partitioned <span class="math inline">\Omega</span></h1>
<p>if <span class="math inline">\Omega</span> can be partitioned into some <span class="math inline">B_1, B_2, B_3, \dots, B_i</span> subsets (<span class="math inline">B_i \cap B_j = \{\}</span>)</p>
<p>then the probability of some event <span class="math inline">A</span> in <span class="math inline">\Omega</span> will be</p>
<p><span class="math display">\displaystyle P(A) = P(A \cap B_1) + P(A \cap B_2) + \dots + P(A \cap B_i)</span></p>
<p>which can be rewritten using the 'given' formula as</p>
<p><span class="math display">\displaystyle \begin{aligned}
P(A) &amp;= P(A \mid B_1)P(B_1)
\\ &amp;+ P(A \mid B_2)P(B_2)
\\ &amp;+ ...
\\ &amp;+ P(A \mid B_i)P(B_i)
\end{aligned}</span></p>
<h2 id="bayes-formula">bayes formula</h2>
<p>useful when figuring <span class="math inline">P(\text{partition of } \Omega \mid \text{any event } A)</span></p>
<p><span class="math display">\displaystyle \begin{aligned}
P(B_k \mid A) &amp;= {P(AB_k) \over P(A)}
\\ &amp;= {P(AB_k) \over {P(A \cap B_1) + P(A \cap B_2) + \dots}}
\\ &amp;= {P(A \mid B_k)P(B_k) \over {P(A \mid B_1)P(B_1) + P(A \mid B_2)P(B_2) + \dots}}
\end{aligned}</span></p>
<p>e.g. when there are only 2 partitions and <span class="math inline">B</span> is one of them</p>
<p><span class="math display">\displaystyle P(B \mid A) = {P(A \mid B)P(B) \over P(A \mid B)P(B) + P(A \mid B^c)P(B^c)}</span></p>
<h1 id="independence">independence</h1>
<p><span class="math inline">A</span> and <span class="math inline">B</span> are independent if</p>
<p><span class="math display">\displaystyle P(A \cap B) = P(A)P(B)</span></p>
<p><span class="math inline">A_1</span>, <span class="math inline">A_2</span>, ..., <span class="math inline">A_n</span> are independent (also called <em>mutually independent</em>) if union of each in-order union equals product of probabilities e.g. <span class="math inline">A</span>, <span class="math inline">B</span>, <span class="math inline">C</span> are independent if</p>
<p><span class="math display">\displaystyle \begin{aligned}
&amp;P(ABC) = P(A)P(B)P(C)
\\ \text{and } &amp;P(AB) = P(A)P(B)
\\ \text{and } &amp;P(AC) = P(A)P(C)
\\ \text{and } &amp;P(BC) = P(B)P(C)
\end{aligned}</span></p>
<h1 id="distributions">distributions</h1>
<p><span class="math inline">X \sim Y</span>: <span class="math inline">X</span> follows <span class="math inline">Y</span></p>
<h2 id="bernoulli-distribution">bernoulli distribution</h2>
<p><span class="math inline">X \sim Ber(p) if</span></p>
<p><span class="math display">\displaystyle \begin{aligned}
P(X = 1) &amp;= p
\\ P(X = 0) &amp;= 1 - p
\end{aligned}</span></p>
<p>it is (weighted) coin flip basically</p>
<h2 id="binomial-distribution">binomial distribution</h2>
<p><span class="math inline">X \sim Bin(n, p)</span> if</p>
<p><span class="math display">\displaystyle P(X = k) = {n \choose k}p^k (1-p)^{n-k}</span></p>
<p><span class="math inline">n</span> is like success prob, <span class="math inline">p</span> is num of times try. and <span class="math inline">k</span> is like how many times it succeeded (no order). note: <span class="math inline">k</span> only makes sense for values <span class="math inline">0..n</span></p>
<h2 id="geometric-distribution">geometric distribution</h2>
<p><span class="math inline">X \sim Geom(p)</span> if</p>
<p><span class="math display">\displaystyle P(X = k) = (1-p)^{k-1}p</span></p>
<p><span class="math inline">p</span> is success prob. so <span class="math inline">k</span> is like how many times it took to succeed for first time. note: <span class="math inline">k</span> only makes sense for values <span class="math inline">1..</span></p>
<h2 id="hypergeometric-distribution">hypergeometric distribution</h2>
<p>i dont think we went over this in class but it showed up one hw problem.</p>
<p>is like specific hw problem picking without replacement, unordered, two possible groups. <span class="math inline">N</span> is num total, <span class="math inline">N_A</span> is num 'success', <span class="math inline">n</span> is how many picking</p>
<p><span class="math inline">X \sim Hypergeom(N, N_A, n)</span> if</p>
<p><span class="math display">\displaystyle P(X = k) = {{N_A \choose k}{N-N_A \choose n-k} \over {N \choose n}}</span></p>
<h1 id="random-variables-1">random variables</h1>
<h2 id="probability-density-function">probability density function</h2>
<ul>
<li><span class="math inline">f(x)</span></li>
<li>like mass function for intervals; take integral of it</li>
<li>always <span class="math inline">\geq 0</span></li>
<li>integral of it everywhere must be <span class="math inline">1</span></li>
</ul>
<h2 id="cumulative-distribution-function">cumulative distribution function</h2>
<p>sum of all probabilities <span class="math inline">\le</span></p>
<h2 id="expectationmean">expectation/mean</h2>
<p>for discrete <span class="math inline">X</span></p>
<p><span class="math display">\displaystyle E[g(X)] = \sum_k g(k)P(X=k)</span></p>
<p>for continuous <span class="math inline">X</span> with density function <span class="math inline">f(x)</span></p>
<p><span class="math display">\displaystyle E[g(X)] = \int_{-\infty}^{\infty} g(x)f(x)dx</span></p>
</body>
</html>
